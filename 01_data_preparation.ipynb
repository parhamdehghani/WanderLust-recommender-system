{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65d883-f2ce-425d-b536-a7ba97ee6cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "!pip install gcsfs -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8536bb11-7df0-4285-9eaa-e12d74f07656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the paths to your data in Google Cloud Storage.\n",
    "bucket_name = 'wanderlust-recommender-system'\n",
    "file_path1 = f'gs://{bucket_name}/Datafiniti_Hotel_Reviews.csv'\n",
    "file_path2 = f'gs://{bucket_name}/Datafiniti_Hotel_Reviews_Jun19.csv'\n",
    "\n",
    "# Load each CSV file into its own pandas DataFrame.\n",
    "try:\n",
    "    df1 = pd.read_csv(file_path1)\n",
    "    df2 = pd.read_csv(file_path2)\n",
    "    print(\"Successfully loaded both CSV files.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "\n",
    "# Combine the two DataFrames into one.\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "print(f\"\\nSuccessfully combined the datasets.\")\n",
    "print(f\"Original size of df1: {len(df1)} rows\")\n",
    "print(f\"Original size of df2: {len(df2)} rows\")\n",
    "print(f\"Size of combined dataset: {len(combined_df)} rows\")\n",
    "\n",
    "# --- Cleaning & Preprocessing ---\n",
    "\n",
    "# Define the columns that are essential for reviews.\n",
    "required_columns = ['reviews.text', 'reviews.rating', 'name', 'reviews.username']\n",
    "\n",
    "# Drop rows that are missing any of these critical values.\n",
    "initial_rows = len(combined_df)\n",
    "combined_df.dropna(subset=required_columns, inplace=True)\n",
    "print(f\"\\nDropped {initial_rows - len(combined_df)} rows with missing required values.\")\n",
    "\n",
    "# Check for and remove duplicate reviews.\n",
    "initial_rows = len(combined_df)\n",
    "combined_df.drop_duplicates(subset=['reviews.text', 'reviews.username'], inplace=True)\n",
    "print(f\"Dropped {initial_rows - len(combined_df)} duplicate reviews.\")\n",
    "\n",
    "\n",
    "# --- Creating Numerical IDs ---\n",
    "combined_df['hotel_id'] = pd.factorize(combined_df['name'])[0]\n",
    "combined_df['user_id'] = pd.factorize(combined_df['reviews.username'])[0]\n",
    "\n",
    "\n",
    "# --- Final Verification ---\n",
    "\n",
    "print(\"\\n--- Final Cleaned DataFrame ---\")\n",
    "combined_df.info()\n",
    "combined_df.head(20)\n",
    "\n",
    "# --- Save the Cleaned DataFrame ---\n",
    "\n",
    "print(\"Saving the final DataFrame to GCS...\")\n",
    "\n",
    "# Define the destination path in the GCS bucket.\n",
    "destination_path = f'gs://{bucket_name}/processed/combined_hotel_reviews.parquet'\n",
    "\n",
    "# Save the DataFrame.\n",
    "combined_df.to_parquet(destination_path)\n",
    "\n",
    "print(f\"Successfully saved to {destination_path}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
