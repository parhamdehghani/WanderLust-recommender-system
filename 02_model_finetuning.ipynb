{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905af55-e073-4dc4-b31f-0495d9309021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Install Libraries ---\n",
    "\n",
    "!pip install sentence-transformers pyarrow gcsfs datasets accelerate>=0.26.0 -q\n",
    "\n",
    "# --- Import Libraries ---\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Load the Processed Data ---\n",
    "bucket_name = 'wanderlust-recommender-system'\n",
    "file_path = f'gs://{bucket_name}/processed/combined_hotel_reviews.parquet'\n",
    "\n",
    "# Load the data from the Parquet file.\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"--- Successfully loaded processed data ---\")\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "# Verify the DataFrame's structure and data types.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a3309-aecb-4c54-9394-10a700af2f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Separate reviews by sentiment ---\n",
    "# We create two lists of reviews: one for positive (rating > 3) and one for negative (rating <= 3).\n",
    "# We also create dictionaries for quick lookup of reviews by hotel ID.\n",
    "positive_reviews_df = df[df[\"reviews.rating\"]>3].copy()\n",
    "negative_reviews_df = df[df[\"reviews.rating\"]<=3].copy()\n",
    "\n",
    "pos_reviews_by_hotel = positive_reviews_df.groupby(\"hotel_id\")[\"reviews.text\"].apply(list).to_dict()\n",
    "neg_reviews_by_hotel = negative_reviews_df.groupby(\"hotel_id\")[\"reviews.text\"].apply(list).to_dict()\n",
    "\n",
    "# --- Generate the training triplets ---\n",
    "train_examples = []\n",
    "# We create 10k of each type for a total of 20k\n",
    "n_examples_per_type = 200 \n",
    "\n",
    "# --- Part A: Create Intra-Hotel (Sentiment-based) Triplets ---\n",
    "print(f\"Generating {n_examples_per_type} Intra-Hotel triplets ...\")\n",
    "\n",
    "# We need hotels that have at least two positive reviews AND at least one negative review.\n",
    "valid_hotels_intra = [hid for hid in pos_reviews_by_hotel if len(pos_reviews_by_hotel.get(hid, [])) > 1 and hid in neg_reviews_by_hotel]\n",
    "\n",
    "for _ in tqdm(range(n_examples_per_type)):\n",
    "    \n",
    "    # Select a hotel that meets our criteria.\n",
    "    hotel_id = random.choice(valid_hotels_intra)\n",
    "    \n",
    "    # Pick two different positive reviews for the anchor and positive.\n",
    "    anchor_review, positive_review = random.sample(pos_reviews_by_hotel[hotel_id], 2)\n",
    "    \n",
    "    # Pick one negative review from the SAME hotel.\n",
    "    negative_review = random.choice(neg_reviews_by_hotel[hotel_id])\n",
    "    \n",
    "    \n",
    "    train_examples.append(InputExample(texts=[anchor_review, positive_review, negative_review]))\n",
    "\n",
    "    # --- Part B: Create Inter-Hotel (Hotel-based) Triplets ---\n",
    "print(f\"Generating {n_examples_per_type} Inter-Hotel triplets ...\")\n",
    "\n",
    "# We need hotels that have at least two positive reviews.\n",
    "\n",
    "valid_hotels_inter = [hid for hid in pos_reviews_by_hotel if len(pos_reviews_by_hotel.get(hid, [])) > 1]\n",
    "\n",
    "\n",
    "for _ in tqdm(range(n_examples_per_type)):\n",
    "    # Pick a hotel for the anchor/positive.\n",
    "    anchor_hotel_id = random.choice(valid_hotels_inter)\n",
    "    \n",
    "    # Pick two different positive reviews.\n",
    "    anchor_review, positive_review = random.sample(pos_reviews_by_hotel[anchor_hotel_id], 2)\n",
    "    \n",
    "    \n",
    "    # Pick a hotel for the negative, ensuring it's a different hotel.\n",
    "    negative_hotel_id = random.choice(valid_hotels_inter)\n",
    "    if negative_hotel_id == anchor_hotel_id:\n",
    "        negative_review_id = random.choice(valid_hotels_inter)\n",
    "    \n",
    "    # Pick a positive review from that DIFFERENT hotel.\n",
    "    negative_review = random.choice(pos_reviews_by_hotel[negative_hotel_id])\n",
    "    \n",
    "    train_examples.append(InputExample(texts=[anchor_review, positive_review, negative_review]))\n",
    "    \n",
    "# --- Shuffle and Verify ---\n",
    "random.shuffle(train_examples)\n",
    "print(f\"Successfully created and shuffled total of {len(train_examples)} triplets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520ef96-78a5-4845-bb84-6ec43d0926e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Define the Model ---\n",
    "# We load a pre-trained model from the sentence-transformers library.\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "# --- Define the DataLoader ---\n",
    "train_batch_size = 8\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "# --- Define the Loss Function ---\n",
    "# We instantiate our TripletLoss function.\n",
    "train_loss = losses.TripletLoss(model=model, triplet_margin=1.0, \\\n",
    "                                distance_metric=losses.TripletDistanceMetric.COSINE )\n",
    "\n",
    "# --- Set Training Parameters ---\n",
    "# Number of epochs 1 or 2 is usually enough to prevent forgetting\n",
    "num_epochs = 1\n",
    "\n",
    "# The 'warmup_steps' parameter as 10% of the training steps is a common choice.\n",
    "warmup_steps = int(len(train_dataloader)*num_epochs*0.1)\n",
    "\n",
    "print(\"--- Model and Trainer Configuration ---\")\n",
    "print(f\"Base Model: {model_name}\")\n",
    "print(f\"Training with {len(train_examples)} triplets\")\n",
    "print(f\"Number of epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {train_batch_size}\")\n",
    "print(f\"Warmup steps: {warmup_steps}\")\n",
    "print(f\"Loss function: TripletLoss with Cosine Distance and margin=1.0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c875e07-a352-4559-ad9d-ee48309d0cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Start Training ---\n",
    "\n",
    "output_path = 'finetuned_hotel_recommender'\n",
    "print(f\"Fine-tunining now begins and the new model will be saved in {output_path}.\")\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader,train_loss)], epochs=num_epochs,\\\n",
    "         warmup_steps=warmup_steps, output_path=output_path, show_progress_bar=True)\n",
    "\n",
    "# Copy local trained model to Google storage bucket\n",
    "!gsutil -m mv {output_path} gs://{bucket_name}/processed/\n",
    "\n",
    "print(\"\\n--- Training Completed ---\")\n",
    "print(f\"New fine-tuned model is saved in {output_path} folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a05af-7f2c-4c32-b06e-ade99fac1cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
